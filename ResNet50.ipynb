{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ljI6Ep9r-Pg6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/archive.zip\"\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_dir = \"/content/train\" # Directory containing the training data\n",
        "test_dir = \"/content/test\"  # Directory containing the validation data\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HbNh3aj0EzWn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
        "from keras.preprocessing import image\n",
        "from keras.initializers import glorot_uniform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6JBri6XAImaJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import skimage.io\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization ,Activation\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSd3yHWDItQn"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   validation_split = 0.2,\n",
        "\n",
        "        rotation_range=5,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        #zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  validation_split = 0.2)\n",
        "\n",
        "test_datagen  = ImageDataGenerator(rescale = 1./255\n",
        "                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aslsx8tYLu0n"
      },
      "outputs": [],
      "source": [
        "train_dataset  = train_datagen.flow_from_directory(directory = '/content/train',\n",
        "                                                   target_size = (48,48),\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   subset = 'training',\n",
        "                                                   batch_size = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8UXdljQLw3t"
      },
      "outputs": [],
      "source": [
        "valid_dataset = valid_datagen.flow_from_directory(directory = '/content/train',\n",
        "                                                  target_size = (48,48),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  subset = 'validation',\n",
        "                                                  batch_size = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWtvtKi0L2yT"
      },
      "outputs": [],
      "source": [
        "test_dataset = test_datagen.flow_from_directory(directory = '/content/test',\n",
        "                                                  target_size = (48,48),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  batch_size = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "idNKYkhQL8nd",
        "outputId": "5fbc23cf-c53b-4bb4-cd37-760020ccfdc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.ResNet50(input_shape=(48,48,3),include_top=False,weights=\"imagenet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Teps7CY9MGKY",
        "outputId": "a35f0ed1-215f-4d70-db89-d57798d4ce66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2, 2, 2048)        23587712  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 2, 2048)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 8192)             32768     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                262176    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32)                0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32)                0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 231       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,885,383\n",
            "Trainable params: 1,335,815\n",
            "Non-trainable params: 22,549,568\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "for layer in base_model.layers[:-4]:\n",
        "    layer.trainable=False\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(7,activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tn8SxtJoZEMV"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "63MGG0XhYtsA",
        "outputId": "11c1f756-6960-4abe-9f30-7a424eb58dde"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b62cb187e490>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0mtrain_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mvalid_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# Train the model with the callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m history = model.fit(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'validation_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 256\n",
        "# Define the callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='model_weights.h5',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "train_num = train_dataset.samples\n",
        "valid_num = validation_dataset.samples\n",
        "# Train the model with the callback\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=train_num // BATCH_SIZE,\n",
        "    epochs=5,\n",
        "    validation_data=valid_dataset,\n",
        "    validation_steps=valid_num // BATCH_SIZE,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R_DxWE6h9523"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "plt.plot(epochs, train_loss, label='Training loss')\n",
        "plt.plot(epochs, val_loss, label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Plot the train and validation accuracy\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, train_acc, label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}